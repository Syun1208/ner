{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "def merge_alpha_params(param1: Dict[str, Any], param2: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Merge two alpha parameter dictionaries by taking non-N/A values from either param\n",
    "    \n",
    "    Args:\n",
    "        param1: First parameter dictionary\n",
    "        param2: Second parameter dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Merged parameter dictionary\n",
    "    \"\"\"\n",
    "    merged = {}\n",
    "    \n",
    "    # List of fields to merge\n",
    "    fields = [\"from_date\", \"to_date\", \"product\", \"product_detail\", \"level\", \"user\"]\n",
    "    \n",
    "    for field in fields:\n",
    "        # Take value from param1 if not N/A, otherwise from param2\n",
    "        if param1.get(field) not in [None, \"N/A\"]:\n",
    "            merged[field] = param1[field]\n",
    "        elif param2.get(field) not in [None, \"N/A\"]:\n",
    "            merged[field] = param2[field]\n",
    "        else:\n",
    "            merged[field] = None\n",
    "            \n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def llm(\n",
    "    user_prompt: str,\n",
    "    system_prompt: str,\n",
    "    format_schema: Dict[str, Any] = None,\n",
    "    api: str = 'https://ollama.selab.edu.vn',\n",
    "    endpoint: str = '/api/chat',\n",
    "    model: str = \"qwen2.5:14b\"\n",
    ") -> Dict[str, str]:\n",
    "    \n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "\n",
    "    if endpoint == '/api/chat' and format_schema is not None:\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"format\": format_schema,\n",
    "            \"stream\": False\n",
    "        }\n",
    "    \n",
    "    elif endpoint == '/api/generate':\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": messages,\n",
    "            \"option\": {\n",
    "              \"temperature\": 0.4  \n",
    "            },\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "    url = f'{api}{endpoint}'\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data, timeout=600)\n",
    "\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Request failed with status {response.status_code}: {response.text}\")\n",
    "\n",
    "    response_data = response.json()\n",
    "    \n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_user_intent(query):\n",
    "    user_prompt = f\"\"\"\n",
    "    \n",
    "    # ***User's query***\n",
    "    {query}\n",
    "\n",
    "    # ***Example Scenarios:***\n",
    "    \n",
    "    - ***User***: \"I want to confirm it\"\n",
    "    - ***Assistant***: {{\"is_confirmed\": 1}}\n",
    "    \n",
    "    - ***User***: \"Yes, delete it.\"\n",
    "    - ***Assistant***: {{\"is_confirmed\": 1}}\n",
    "\n",
    "    - ***User***: \"No, I changed my mind.\"\n",
    "    - ***Assistant***: {{\"is_confirmed\": 0}}\n",
    "\n",
    "    - ***User***: \"Yes, that's correct.\"\n",
    "    - ***Assistant***: {{\"is_confirmed\": 1}}\n",
    "\n",
    "    - ***User***: \"No, I meant for the last week.\"\n",
    "    - ***Assistant***: {{\"is_confirmed\": 0}}\n",
    "    \"\"\"\n",
    "    return user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirmation_agent(\n",
    "    query: str\n",
    ") -> Dict[str, str]:\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are agent detecting the confirmation from user's query, you need to consistently detect and recognize whether user confirms or not.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = confirm_user_intent(query)\n",
    "    \n",
    "    format_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"is_confirmed\": {\n",
    "                \"type\": \"integer\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"is_confirmed\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    response = llm(\n",
    "        user_prompt=user_prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        format_schema=format_schema,\n",
    "        endpoint='/api/chat'\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = confirmation_agent(\n",
    "    query='I am so scared, I am not sure'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_confirmed': 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_task_intent(query):\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "    \n",
    "    # ***User's query***\n",
    "    {query}\n",
    "\n",
    "    \n",
    "    # **Key Guidelines:**\n",
    "    - Match the user's query to one of the predefined task types listed below.\n",
    "    - If the query does not match any task type, respond with \"Task type not recognized.\"\n",
    "    - Provide a concise summary of the detected task type for confirmation.\n",
    "    - Respond in a polite and professional tone, maintaining a focus on accuracy and helpfulness.\n",
    "\n",
    "    # ***Predefined Task Types:***\n",
    "    - Winlost Report\n",
    "    - Turnover Report\n",
    "    - Bet Count Report\n",
    "    - Net Turnover Report\n",
    "    - Gross Commission\n",
    "    - Member Report\n",
    "    - Agent Report\n",
    "    - Master Report\n",
    "    - Super Report\n",
    "    - Company Report\n",
    "    - Reward (USD) Report\n",
    "    - Customer / Username Report\n",
    "    - Outstanding Report\n",
    "    - Statement Report\n",
    "    - Create a new customer information (account/member/agent/master/super)\n",
    "    - Bet List Management\n",
    "    - Bet Forecasting\n",
    "    - Transfers\n",
    "    - Risk Management\n",
    "\n",
    "    # ***Example Scenarios:***\n",
    "    - ***User***: \"I want to get winlost and turnover report.\"\n",
    "    - ***Assistant***: [\"Winlost Report\", \"Turnover Report\"]\n",
    "\n",
    "    - ***User***: \"Generate a member and agent report.\"\n",
    "    - ***Assistant***: [\"Member Report\", \"Agent Report\"]\n",
    "\n",
    "    - ***User***: \"I need a statement and risk management report.\"\n",
    "    - ***Assistant***: [\"Statement Report\", \"Risk Management\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_detection_agent(\n",
    "    query: str\n",
    ") -> Dict[str, str]:\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are a task detection agent responsible for identifying and categorizing the type of task requested by the user. Your primary goal is to determine whether the user's query matches one of the predefined task types and confirm the detected task type explicitly.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = detect_task_intent(query)\n",
    "    \n",
    "    format_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"tasks\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"tasks\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    response = llm(\n",
    "        user_prompt=user_prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        format_schema=format_schema,\n",
    "        endpoint='/api/chat'\n",
    "    )\n",
    "    \n",
    "    return json.loads(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = task_detection_agent(\n",
    "    query='I want to get Winlost Report please'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tasks': ['Winlost Report']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I can help with that. To generate a Winlost Report for day 10 (which would be April 10th, 2025), we need to confirm the following details:\n",
      "\n",
      "- **Start Date**: `from_date` will be set as \"2025-04-10\".\n",
      "- **End Date**: `to_date` will also be set as \"2025-04-10\".\n",
      "- **Level**: The level can be selected from the options provided. If you're not sure, we'll use \"All\" for now.\n",
      "- **Product**: Similar to the level, if a specific product is required or preferred, please let me know; otherwise, I will use \"All\".\n",
      "- **User**: If this report is requested for a particular user or all users under a certain hierarchy, specify the user ID here.\n",
      "\n",
      "Could you confirm these details? Specifically:\n",
      "1. Are there any particular levels or products you want to focus on?\n",
      "2. Do you need the report for a specific user or should it include data from all users?\n",
      "\n",
      "Once I have confirmation, I'll proceed with generating the Winlost Report.\n"
     ]
    }
   ],
   "source": [
    "print(\"Sure, I can help with that. To generate a Winlost Report for day 10 (which would be April 10th, 2025), we need to confirm the following details:\\n\\n- **Start Date**: `from_date` will be set as \\\"2025-04-10\\\".\\n- **End Date**: `to_date` will also be set as \\\"2025-04-10\\\".\\n- **Level**: The level can be selected from the options provided. If you're not sure, we'll use \\\"All\\\" for now.\\n- **Product**: Similar to the level, if a specific product is required or preferred, please let me know; otherwise, I will use \\\"All\\\".\\n- **User**: If this report is requested for a particular user or all users under a certain hierarchy, specify the user ID here.\\n\\nCould you confirm these details? Specifically:\\n1. Are there any particular levels or products you want to focus on?\\n2. Do you need the report for a specific user or should it include data from all users?\\n\\nOnce I have confirmation, I'll proceed with generating the Winlost Report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
