{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def llm(\n",
    "    messages: str,\n",
    "    format_schema: Dict[str, Any] = None,\n",
    "    api: str = 'https://ollama.selab.edu.vn',\n",
    "    endpoint: str = '/api/chat',\n",
    "    model: str = \"qwen2.5:14b\"\n",
    ") -> Dict[str, str]:\n",
    "    \n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "\n",
    "    if endpoint == '/api/chat' and format_schema is not None:\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"format\": format_schema,\n",
    "            \"stream\": False\n",
    "        }\n",
    "    \n",
    "    elif endpoint == '/api/generate':\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": messages,\n",
    "            \"option\": {\n",
    "              \"temperature\": 0.4  \n",
    "            },\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "    url = f'{api}{endpoint}'\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data, timeout=600)\n",
    "\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Request failed with status {response.status_code}: {response.text}\")\n",
    "\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict\n",
    "\n",
    "def greeting_checker_user_intent(query: str) -> str:\n",
    "    user_prompt = f\"\"\"\n",
    "\n",
    "    # ***User's query***\n",
    "    {query}\n",
    "    \n",
    "    # General conversation guidelines:\n",
    "    - Your task is to check if the user's query is a greeting conversation or not.\n",
    "    - The user's query must be greeting conversation when the user's query is not related to any report question.\n",
    "    - If the user's query is a greeting conversation, return 1.\n",
    "    - If the user's query is not a greeting conversation, return 0.\n",
    "    - The response should be in JSON format.\n",
    "    \n",
    "\n",
    "    # ***Example Scenarios:***\n",
    "    \n",
    "    - ***User***: \"Hello bot how are you today ?\"\n",
    "    - ***Assistant***: {{\"is_normal_conversation\": 1}}\n",
    "    \n",
    "    - ***User***: \"See you later. Bye.\"\n",
    "    - ***Assistant***: {{\"is_normal_conversation\": 1}}\n",
    "\n",
    "    - ***User***: \"I want change to a little bit, I want to get Product Virtual Sports and product detail Saba Basketball with user level Super Agent\"\n",
    "    - ***Assistant***: {{\"is_normal_conversation\": 0}}\n",
    "\n",
    "    - ***User***: \"I want to get Winlost Report\"\n",
    "    - ***Assistant***: {{\"is_normal_conversation\": 0}}\n",
    "\n",
    "    - ***User***: \"Hey what is the weather in Tokyo?\"\n",
    "    - ***Assistant***: {{\"is_normal_conversation\": 1}}\n",
    "    \"\"\"\n",
    "    return user_prompt\n",
    "\n",
    "\n",
    "def get_decision(\n",
    "    query: str\n",
    ") -> Dict[str, str]:\n",
    "    system_prompt = \"\"\"\n",
    "    You are a helpful assistant that can check if the user's query is a greeting conversation or not.\n",
    "    \n",
    "    # General conversation guidelines:\n",
    "    - The user's query must be greeting conversation when the user's query is not related to any report question.\n",
    "    - If the user's query is a greeting conversation, return 1.\n",
    "    - If the user's query is not a greeting conversation, return 0.\n",
    "    - The response should be in JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = greeting_checker_user_intent(query)\n",
    "\n",
    "    format_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"is_normal_conversation\": {\n",
    "                \"type\": \"integer\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"is_normal_conversation\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = llm(\n",
    "        messages=messages,\n",
    "        format_schema=format_schema\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_decision(\"Oke bot let's do it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response.json()['message']['content'])['is_normal_conversation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
